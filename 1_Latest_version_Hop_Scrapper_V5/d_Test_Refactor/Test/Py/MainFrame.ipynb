{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyCaller import process_urls\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_print_results(url):\n",
    "    print(f\"Processing URL: {url}\")\n",
    "    data = process_urls([url])\n",
    "\n",
    "    if data:\n",
    "        print(f\"\\nResults for URL: {url}\")\n",
    "        for key, df in data.items():\n",
    "            if df is not None and not df.empty:\n",
    "                print(f\"{key.replace('_', ' ').title()}:\")\n",
    "                print(\"\\n\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found for URL: {url}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Load initial URLs\n",
    "    all_found_urls_s = pd.read_csv(\"all_found_urls_23.12.23_cleaned.csv\")\n",
    "    initial_urls = list(set(all_found_urls_s[\"0\"]))[:10]\n",
    "\n",
    "    # Initialize DataFrames\n",
    "    all_pole_studio_data = pd.DataFrame()\n",
    "    all_workshops_data = pd.DataFrame()\n",
    "    all_workshop_details_data = pd.DataFrame()\n",
    "\n",
    "    # Process each URL\n",
    "    total_urls = len(initial_urls)\n",
    "    for i, url in tqdm(enumerate(initial_urls, start=1), total=total_urls, desc=\"Processing URLs\"):\n",
    "        print(f\"Processing URL {i}/{total_urls}: {url}\")\n",
    "        data = process_and_print_results(url)\n",
    "        if data:\n",
    "            # Add data to corresponding DataFrames\n",
    "            if 'pole_studio_data' in data and not data['pole_studio_data'].empty:\n",
    "                all_pole_studio_data = pd.concat([all_pole_studio_data, data['pole_studio_data']], ignore_index=True)\n",
    "            \n",
    "            if 'workshops_data' in data and not data['workshops_data'].empty:\n",
    "                all_workshops_data = pd.concat([all_workshops_data, data['workshops_data']], ignore_index=True)\n",
    "            \n",
    "            if 'workshop_details' in data and not data['workshop_details'].empty:\n",
    "                all_workshop_details_data = pd.concat([all_workshop_details_data, data['workshop_details']], ignore_index=True)\n",
    "\n",
    "        # Display progress\n",
    "        progress_percent = (i / total_urls) * 100\n",
    "        print(f\"Progress: {progress_percent:.2f}%\\n\")\n",
    "\n",
    "    # # Export DataFrames to CSV files\n",
    "    # all_pole_studio_data.to_csv(\"Pole_Studio_Übersicht_S.csv\", index=False)\n",
    "    # all_workshops_data.to_csv(\"Workshop_Liste_SW.csv\", index=False)\n",
    "    # all_workshop_details_data.to_csv(\"Workshop_Übersicht_E.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URLS Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_and_unique_urls(file_path):\n",
    "    # Read the CSV file\n",
    "    all_found_urls_s = pd.read_csv(file_path, header=None, names=['index', 'url'])\n",
    "\n",
    "    # Ensure all URLs are in lowercase\n",
    "    all_found_urls_s['url'] = all_found_urls_s['url'].str.lower()\n",
    "\n",
    "    # Remove duplicate URLs\n",
    "    all_found_urls_s = all_found_urls_s.drop_duplicates(subset=['url'])\n",
    "\n",
    "    # Save the cleaned and unique URLs to a new CSV file\n",
    "    cleaned_file_path = file_path.replace('.csv', '_cleaned.csv')\n",
    "    all_found_urls_s.to_csv(cleaned_file_path, index=False, header=False)\n",
    "\n",
    "    return cleaned_file_path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file_path = \"all_found_urls_23.12.23.csv\"\n",
    "    cleaned_file_path = clean_and_unique_urls(input_file_path)\n",
    "    print(f\"Cleaned and unique URLs saved to: {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyCaller import process_urls\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_print_results(url):\n",
    "    data = process_urls([url])\n",
    "\n",
    "    if data:\n",
    "        for key, df in data.items():\n",
    "            if df is not None and not df.empty:\n",
    "                print(f\"{key.replace('_', ' ').title()}: {len(df)} entries\")\n",
    "\n",
    "def main():\n",
    "    # Load initial URLs\n",
    "    all_found_urls_s = pd.read_csv(\"all_found_urls_23.12.23_cleaned.csv\")\n",
    "    initial_urls = list(set(all_found_urls_s[\"0\"]))[:100]\n",
    "\n",
    "    # Initialize DataFrames\n",
    "    all_pole_studio_data = pd.DataFrame()\n",
    "    all_workshops_data = pd.DataFrame()\n",
    "    all_workshop_details_data = pd.DataFrame()\n",
    "\n",
    "    # Process each URL\n",
    "    total_urls = len(initial_urls)\n",
    "    with tqdm(total=total_urls, desc=\"Processing URLs\") as pbar:\n",
    "        for i, url in enumerate(initial_urls, start=1):\n",
    "            process_and_print_results(url)\n",
    "            pbar.update(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  10%|█         | 1/10 [00:02<00:22,  2.45s/it, Current URL: https://www.eversports.de/s/dance-%26-fly-pole-studio]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during HTTP request: 404 Client Error: Not Found for url: https://www.eversports.de/s/dance-%26-fly-pole-studio\n",
      "Converting to DataFrame...\n",
      "Validating URLs...\n",
      "Processing completed.\n",
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  20%|██        | 2/10 [00:03<00:15,  1.90s/it, Current URL: https://www.eversports.de/s/polefriends]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during HTTP request: 404 Client Error: Not Found for url: https://www.eversports.de/s/polefriends\n",
      "Converting to DataFrame...\n",
      "Validating URLs...\n",
      "Processing completed.\n",
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 22:36:30,196 - INFO - Processing URL 1/3: https://www.eversports.de/s/loft1-basel-city\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to DataFrame...\n",
      "Validating URLs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 22:36:31,784 - INFO - URL https://www.eversports.de/s/loft1-basel-city is valid.\n",
      "2024-02-02 22:36:31,785 - INFO - Processing URL 2/3: https://www.eversports.de/sp/loft1-basel-city\n",
      "2024-02-02 22:36:33,087 - INFO - URL https://www.eversports.de/sp/loft1-basel-city is not valid.\n",
      "2024-02-02 22:36:33,089 - INFO - Processing URL 3/3: https://www.eversports.de/s/loft1-basel-city/team\n",
      "2024-02-02 22:36:34,384 - INFO - URL https://www.eversports.de/s/loft1-basel-city/team is valid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Pole Studio Data from https://www.eversports.de/s/loft1-basel-city...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  30%|███       | 3/10 [00:11<00:30,  4.32s/it, Current URL: https://www.eversports.de/s/loft1-basel-city]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed.\n",
      "Pole Studio Data: 1 entries\n",
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  40%|████      | 4/10 [00:12<00:18,  3.10s/it, Current URL: https://www.eversports.de/s/move-with-ana]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during HTTP request: 404 Client Error: Not Found for url: https://www.eversports.de/s/move-with-ana\n",
      "Converting to DataFrame...\n",
      "Validating URLs...\n",
      "Processing completed.\n",
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  50%|█████     | 5/10 [00:13<00:12,  2.46s/it, Current URL: https://www.eversports.de/s/luftfabrik-dresden]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during HTTP request: 404 Client Error: Not Found for url: https://www.eversports.de/s/luftfabrik-dresden\n",
      "Converting to DataFrame...\n",
      "Validating URLs...\n",
      "Processing completed.\n",
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 22:36:39,892 - INFO - Processing URL 1/3: https://www.eversports.de/s/tanzschule-poledance-reutlingen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to DataFrame...\n",
      "Validating URLs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 22:36:41,392 - INFO - URL https://www.eversports.de/s/tanzschule-poledance-reutlingen is valid.\n",
      "2024-02-02 22:36:41,394 - INFO - Processing URL 2/3: https://www.eversports.de/sp/tanzschule-poledance-reutlingen\n",
      "2024-02-02 22:36:42,608 - INFO - URL https://www.eversports.de/sp/tanzschule-poledance-reutlingen is valid.\n",
      "2024-02-02 22:36:42,609 - INFO - Processing URL 3/3: https://www.eversports.de/s/tanzschule-poledance-reutlingen/team\n",
      "2024-02-02 22:36:44,480 - INFO - URL https://www.eversports.de/s/tanzschule-poledance-reutlingen/team is valid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Pole Studio Data from https://www.eversports.de/s/tanzschule-poledance-reutlingen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  60%|██████    | 6/10 [00:20<00:15,  3.88s/it, Current URL: https://www.eversports.de/s/tanzschule-poledance-reutlingen]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed.\n",
      "Pole Studio Data: 1 entries\n",
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  70%|███████   | 7/10 [00:24<00:12,  4.02s/it, Current URL: https://www.eversports.de/s/polesports-studio-l%c3%bcneburg]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during HTTP request: Exceeded 30 redirects.\n",
      "Converting to DataFrame...\n",
      "Validating URLs...\n",
      "Processing completed.\n",
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  80%|████████  | 8/10 [00:28<00:07,  3.90s/it, Current URL: https://www.eversports.de/s/schönheitstanz-studio]          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during HTTP request: Exceeded 30 redirects.\n",
      "Converting to DataFrame...\n",
      "Validating URLs...\n",
      "Processing completed.\n",
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs:  90%|█████████ | 9/10 [00:32<00:03,  3.94s/it, Current URL: https://www.eversports.de/s/dance-moves-wolfenb%c3%bcttel]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during HTTP request: Exceeded 30 redirects.\n",
      "Converting to DataFrame...\n",
      "Validating URLs...\n",
      "Processing completed.\n",
      "Starting URL reconstruction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing URLs: 100%|██████████| 10/10 [00:33<00:00,  3.35s/it, Current URL: https://www.eversports.de/s/health-and-shape]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during HTTP request: 404 Client Error: Not Found for url: https://www.eversports.de/s/health-and-shape\n",
      "Converting to DataFrame...\n",
      "Validating URLs...\n",
      "Processing completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PyCaller import process_urls\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_print_results(url, all_pole_studio_data, all_workshops_data, all_workshop_details_data):\n",
    "    data = process_urls([url])\n",
    "\n",
    "    if data:\n",
    "        for key, df in data.items():\n",
    "            if df is not None and not df.empty:\n",
    "                print(f\"{key.replace('_', ' ').title()}: {len(df)} entries\")\n",
    "\n",
    "                # Update the appropriate DataFrame\n",
    "                if key == 'pole_studio_data':\n",
    "                    all_pole_studio_data = pd.concat([all_pole_studio_data, df], ignore_index=True)\n",
    "                elif key == 'workshops_data':\n",
    "                    all_workshops_data = pd.concat([all_workshops_data, df], ignore_index=True)\n",
    "                elif key == 'workshop_details':\n",
    "                    all_workshop_details_data = pd.concat([all_workshop_details_data, df], ignore_index=True)\n",
    "\n",
    "    return all_pole_studio_data, all_workshops_data, all_workshop_details_data\n",
    "\n",
    "def main():\n",
    "    # Load initial URLs\n",
    "    all_found_urls_s = pd.read_csv(\"all_found_urls_23.12.23_cleaned.csv\")\n",
    "    initial_urls = list(set(all_found_urls_s[\"0\"]))[:10]\n",
    "\n",
    "    # Initialize DataFrames\n",
    "    all_pole_studio_data = pd.DataFrame()\n",
    "    all_workshops_data = pd.DataFrame()\n",
    "    all_workshop_details_data = pd.DataFrame()\n",
    "\n",
    "    # Process each URL with tqdm\n",
    "    with tqdm(total=len(initial_urls), desc=\"Processing URLs\", dynamic_ncols=True) as pbar:\n",
    "        for url in initial_urls:\n",
    "            all_pole_studio_data, all_workshops_data, all_workshop_details_data = process_and_print_results(\n",
    "                url, all_pole_studio_data, all_workshops_data, all_workshop_details_data\n",
    "            )\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Current URL: {url}\", refresh=True)\n",
    "\n",
    "    # # Export DataFrames to CSV files\n",
    "    # all_pole_studio_data.to_csv(\"Pole_Studio_Übersicht_S.csv\", index=False)\n",
    "    # all_workshops_data.to_csv(\"Workshop_Liste_SW.csv\", index=False)\n",
    "    # all_workshop_details_data.to_csv(\"Workshop_Übersicht_E.csv\", index=False)\n",
    "\n",
    "    # Return the final DataFrames\n",
    "    return all_pole_studio_data, all_workshops_data, all_workshop_details_data\n",
    "\n",
    "# Run the main function and get the final DataFrames\n",
    "result_pole_studio, result_workshops, result_workshop_details = main()\n",
    "\n",
    "# Now you can access result_pole_studio, result_workshops, and result_workshop_details outside the function\n",
    "# print(result_pole_studio)\n",
    "# print(result_workshops)\n",
    "# print(result_workshop_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PoleStudio_Name</th>\n",
       "      <th>Adresse</th>\n",
       "      <th>PLZ</th>\n",
       "      <th>Stadt</th>\n",
       "      <th>Straße</th>\n",
       "      <th>Buttons</th>\n",
       "      <th>Pole Studio Beschreibung</th>\n",
       "      <th>E-Mail</th>\n",
       "      <th>Homepage</th>\n",
       "      <th>Telefon</th>\n",
       "      <th>URL_S</th>\n",
       "      <th>Art</th>\n",
       "      <th>Angebot</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Updated Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOFT1 BASEL CITY</td>\n",
       "      <td>[Centralbahnplatz 10 ,  4051 Basel]</td>\n",
       "      <td>4051</td>\n",
       "      <td>Basel</td>\n",
       "      <td>Centralbahnplatz 10</td>\n",
       "      <td>[Übersicht, Klassen, Videos, Preise, Team]</td>\n",
       "      <td>Hell und freundlich und mit 13 Stangen ausgest...</td>\n",
       "      <td>info@loft1.ch</td>\n",
       "      <td>https://www.loft1.ch/studio-basel-2-2/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.eversports.de/s/loft1-basel-city</td>\n",
       "      <td>[Fitness, Poledance, Poledance, Fitness, Fitne...</td>\n",
       "      <td>2 Angebote für Neukund:innen</td>\n",
       "      <td>2024-02-02 22:36:35</td>\n",
       "      <td>2024-02-02 22:36:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanzschule Poledance Reutlingen</td>\n",
       "      <td>[Uhlandstraße 60 ,  72793 Pfullingen]</td>\n",
       "      <td>72793</td>\n",
       "      <td>Pfullingen</td>\n",
       "      <td>Uhlandstraße 60</td>\n",
       "      <td>[Übersicht, Klassen, Videos, Preise, Team]</td>\n",
       "      <td>Die Tanzschule Poledance Reutlingen befindet s...</td>\n",
       "      <td>info@poledance-reutlingen.de</td>\n",
       "      <td>https://www.poledance-reutlingen.de</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.eversports.de/s/tanzschule-poledan...</td>\n",
       "      <td>[Rückenfit, Poledance, Poledance, Crossbody (H...</td>\n",
       "      <td>1 Angebot für Neukund:innen</td>\n",
       "      <td>2024-02-02 22:36:45</td>\n",
       "      <td>2024-02-02 22:36:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PoleStudio_Name                                Adresse  \\\n",
       "0                 LOFT1 BASEL CITY    [Centralbahnplatz 10 ,  4051 Basel]   \n",
       "1  Tanzschule Poledance Reutlingen  [Uhlandstraße 60 ,  72793 Pfullingen]   \n",
       "\n",
       "     PLZ       Stadt                Straße  \\\n",
       "0   4051       Basel  Centralbahnplatz 10    \n",
       "1  72793  Pfullingen      Uhlandstraße 60    \n",
       "\n",
       "                                      Buttons  \\\n",
       "0  [Übersicht, Klassen, Videos, Preise, Team]   \n",
       "1  [Übersicht, Klassen, Videos, Preise, Team]   \n",
       "\n",
       "                            Pole Studio Beschreibung  \\\n",
       "0  Hell und freundlich und mit 13 Stangen ausgest...   \n",
       "1  Die Tanzschule Poledance Reutlingen befindet s...   \n",
       "\n",
       "                          E-Mail                                Homepage  \\\n",
       "0                  info@loft1.ch  https://www.loft1.ch/studio-basel-2-2/   \n",
       "1   info@poledance-reutlingen.de     https://www.poledance-reutlingen.de   \n",
       "\n",
       "  Telefon                                              URL_S  \\\n",
       "0    None       https://www.eversports.de/s/loft1-basel-city   \n",
       "1    None  https://www.eversports.de/s/tanzschule-poledan...   \n",
       "\n",
       "                                                 Art  \\\n",
       "0  [Fitness, Poledance, Poledance, Fitness, Fitne...   \n",
       "1  [Rückenfit, Poledance, Poledance, Crossbody (H...   \n",
       "\n",
       "                        Angebot         Created Date         Updated Date  \n",
       "0  2 Angebote für Neukund:innen  2024-02-02 22:36:35  2024-02-02 22:36:35  \n",
       "1   1 Angebot für Neukund:innen  2024-02-02 22:36:45  2024-02-02 22:36:45  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pole_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_workshop_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'validated_urls' from 'b_URLS_Validation' (c:\\Users\\hamud\\Documents\\GitHub\\1_Latest_version_Hop_Scrapper_V5\\d_Test_Refactor\\Test\\Py\\b_URLS_Validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mb_URLS_Validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validated_urls\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'validated_urls' from 'b_URLS_Validation' (c:\\Users\\hamud\\Documents\\GitHub\\1_Latest_version_Hop_Scrapper_V5\\d_Test_Refactor\\Test\\Py\\b_URLS_Validation.py)"
     ]
    }
   ],
   "source": [
    "from b_URLS_Validation import validated_urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
