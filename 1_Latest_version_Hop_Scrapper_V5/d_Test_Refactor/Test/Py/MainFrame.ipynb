{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyCaller import process_urls\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_print_results(url):\n",
    "    print(f\"Processing URL: {url}\")\n",
    "    data = process_urls([url])\n",
    "\n",
    "    if data:\n",
    "        print(f\"\\nResults for URL: {url}\")\n",
    "        for key, df in data.items():\n",
    "            if df is not None and not df.empty:\n",
    "                print(f\"{key.replace('_', ' ').title()}:\")\n",
    "                print(\"\\n\")\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"No data found for URL: {url}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    # Load initial URLs\n",
    "    all_found_urls_s = pd.read_csv(\"all_found_urls_23.12.23_cleaned.csv\")\n",
    "    initial_urls = list(set(all_found_urls_s[\"0\"]))[:10]\n",
    "\n",
    "    # Initialize DataFrames\n",
    "    all_pole_studio_data = pd.DataFrame()\n",
    "    all_workshops_data = pd.DataFrame()\n",
    "    all_workshop_details_data = pd.DataFrame()\n",
    "\n",
    "    # Process each URL\n",
    "    total_urls = len(initial_urls)\n",
    "    for i, url in tqdm(enumerate(initial_urls, start=1), total=total_urls, desc=\"Processing URLs\"):\n",
    "        print(f\"Processing URL {i}/{total_urls}: {url}\")\n",
    "        data = process_and_print_results(url)\n",
    "        if data:\n",
    "            # Add data to corresponding DataFrames\n",
    "            if 'pole_studio_data' in data and not data['pole_studio_data'].empty:\n",
    "                all_pole_studio_data = pd.concat([all_pole_studio_data, data['pole_studio_data']], ignore_index=True)\n",
    "            \n",
    "            if 'workshops_data' in data and not data['workshops_data'].empty:\n",
    "                all_workshops_data = pd.concat([all_workshops_data, data['workshops_data']], ignore_index=True)\n",
    "            \n",
    "            if 'workshop_details' in data and not data['workshop_details'].empty:\n",
    "                all_workshop_details_data = pd.concat([all_workshop_details_data, data['workshop_details']], ignore_index=True)\n",
    "\n",
    "        # Display progress\n",
    "        progress_percent = (i / total_urls) * 100\n",
    "        print(f\"Progress: {progress_percent:.2f}%\\n\")\n",
    "\n",
    "    # # Export DataFrames to CSV files\n",
    "    # all_pole_studio_data.to_csv(\"Pole_Studio_Übersicht_S.csv\", index=False)\n",
    "    # all_workshops_data.to_csv(\"Workshop_Liste_SW.csv\", index=False)\n",
    "    # all_workshop_details_data.to_csv(\"Workshop_Übersicht_E.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URLS Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_and_unique_urls(file_path):\n",
    "    # Read the CSV file\n",
    "    all_found_urls_s = pd.read_csv(file_path, header=None, names=['index', 'url'])\n",
    "\n",
    "    # Ensure all URLs are in lowercase\n",
    "    all_found_urls_s['url'] = all_found_urls_s['url'].str.lower()\n",
    "\n",
    "    # Remove duplicate URLs\n",
    "    all_found_urls_s = all_found_urls_s.drop_duplicates(subset=['url'])\n",
    "\n",
    "    # Save the cleaned and unique URLs to a new CSV file\n",
    "    cleaned_file_path = file_path.replace('.csv', '_cleaned.csv')\n",
    "    all_found_urls_s.to_csv(cleaned_file_path, index=False, header=False)\n",
    "\n",
    "    return cleaned_file_path\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    input_file_path = \"all_found_urls_23.12.23.csv\"\n",
    "    cleaned_file_path = clean_and_unique_urls(input_file_path)\n",
    "    print(f\"Cleaned and unique URLs saved to: {cleaned_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PyCaller import process_urls\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_print_results(url):\n",
    "    data = process_urls([url])\n",
    "\n",
    "    if data:\n",
    "        for key, df in data.items():\n",
    "            if df is not None and not df.empty:\n",
    "                print(f\"{key.replace('_', ' ').title()}: {len(df)} entries\")\n",
    "\n",
    "def main():\n",
    "    # Load initial URLs\n",
    "    all_found_urls_s = pd.read_csv(\"all_found_urls_23.12.23_cleaned.csv\")\n",
    "    initial_urls = list(set(all_found_urls_s[\"0\"]))[:100]\n",
    "\n",
    "    # Initialize DataFrames\n",
    "    all_pole_studio_data = pd.DataFrame()\n",
    "    all_workshops_data = pd.DataFrame()\n",
    "    all_workshop_details_data = pd.DataFrame()\n",
    "\n",
    "    # Process each URL\n",
    "    total_urls = len(initial_urls)\n",
    "    with tqdm(total=total_urls, desc=\"Processing URLs\") as pbar:\n",
    "        for i, url in enumerate(initial_urls, start=1):\n",
    "            process_and_print_results(url)\n",
    "            pbar.update(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_pole_studio_data, all_workshops_data, all_workshop_details_data\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Run the main function and get the final DataFrames\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m result_pole_studio, result_workshops, result_workshop_details \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Now you can access result_pole_studio, result_workshops, and result_workshop_details outside the function\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# print(result_pole_studio)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# print(result_workshops)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# print(result_workshop_details)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Load initial URLs\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     all_found_urls_s \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_found_urls_23.12.23_cleaned_cleaned.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m     initial_urls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[43mall_found_urls_s\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Initialize DataFrames\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     all_pole_studio_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PyCaller import process_urls\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_and_print_results(url, all_pole_studio_data, all_workshops_data, all_workshop_details_data):\n",
    "    data = process_urls([url])\n",
    "\n",
    "    if data:\n",
    "        for key, df in data.items():\n",
    "            if df is not None and not df.empty:\n",
    "                print(f\"{key.replace('_', ' ').title()}: {len(df)} entries\")\n",
    "\n",
    "                # Update the appropriate DataFrame\n",
    "                if key == 'pole_studio_data':\n",
    "                    all_pole_studio_data = pd.concat([all_pole_studio_data, df], ignore_index=True)\n",
    "                elif key == 'workshops_data':\n",
    "                    all_workshops_data = pd.concat([all_workshops_data, df], ignore_index=True)\n",
    "                elif key == 'workshop_details':\n",
    "                    all_workshop_details_data = pd.concat([all_workshop_details_data, df], ignore_index=True)\n",
    "\n",
    "    return all_pole_studio_data, all_workshops_data, all_workshop_details_data\n",
    "\n",
    "def main():\n",
    "    # Load initial URLs\n",
    "    all_found_urls_s = pd.read_csv(\"all_found_urls_23.12.23_cleaned_cleaned.csv\")\n",
    "    initial_urls = list(set(all_found_urls_s[\"0\"]))\n",
    "\n",
    "    # Initialize DataFrames\n",
    "    all_pole_studio_data = pd.DataFrame()\n",
    "    all_workshops_data = pd.DataFrame()\n",
    "    all_workshop_details_data = pd.DataFrame()\n",
    "\n",
    "    # Process each URL with tqdm\n",
    "    with tqdm(total=len(initial_urls), desc=\"Processing URLs\", dynamic_ncols=True) as pbar:\n",
    "        for url in initial_urls:\n",
    "            all_pole_studio_data, all_workshops_data, all_workshop_details_data = process_and_print_results(\n",
    "                url, all_pole_studio_data, all_workshops_data, all_workshop_details_data\n",
    "            )\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Current URL: {url}\", refresh=True)\n",
    "\n",
    "    # # Export DataFrames to CSV files\n",
    "    # all_pole_studio_data.to_csv(\"Pole_Studio_Übersicht_S.csv\", index=False)\n",
    "    # all_workshops_data.to_csv(\"Workshop_Liste_SW.csv\", index=False)\n",
    "    # all_workshop_details_data.to_csv(\"Workshop_Übersicht_E.csv\", index=False)\n",
    "\n",
    "    # Return the final DataFrames\n",
    "    return all_pole_studio_data, all_workshops_data, all_workshop_details_data\n",
    "\n",
    "# Run the main function and get the final DataFrames\n",
    "result_pole_studio, result_workshops, result_workshop_details = main()\n",
    "\n",
    "# Now you can access result_pole_studio, result_workshops, and result_workshop_details outside the function\n",
    "# print(result_pole_studio)\n",
    "# print(result_workshops)\n",
    "# print(result_workshop_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PoleStudio_Name</th>\n",
       "      <th>Adresse</th>\n",
       "      <th>PLZ</th>\n",
       "      <th>Stadt</th>\n",
       "      <th>Straße</th>\n",
       "      <th>Buttons</th>\n",
       "      <th>Pole Studio Beschreibung</th>\n",
       "      <th>E-Mail</th>\n",
       "      <th>Homepage</th>\n",
       "      <th>Telefon</th>\n",
       "      <th>URL_S</th>\n",
       "      <th>Art</th>\n",
       "      <th>Angebot</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Updated Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOFT1 BASEL CITY</td>\n",
       "      <td>[Centralbahnplatz 10 ,  4051 Basel]</td>\n",
       "      <td>4051</td>\n",
       "      <td>Basel</td>\n",
       "      <td>Centralbahnplatz 10</td>\n",
       "      <td>[Übersicht, Klassen, Videos, Preise, Team]</td>\n",
       "      <td>Hell und freundlich und mit 13 Stangen ausgest...</td>\n",
       "      <td>info@loft1.ch</td>\n",
       "      <td>https://www.loft1.ch/studio-basel-2-2/</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.eversports.de/s/loft1-basel-city</td>\n",
       "      <td>[Fitness, Poledance, Poledance, Fitness, Fitne...</td>\n",
       "      <td>2 Angebote für Neukund:innen</td>\n",
       "      <td>2024-02-02 22:36:35</td>\n",
       "      <td>2024-02-02 22:36:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tanzschule Poledance Reutlingen</td>\n",
       "      <td>[Uhlandstraße 60 ,  72793 Pfullingen]</td>\n",
       "      <td>72793</td>\n",
       "      <td>Pfullingen</td>\n",
       "      <td>Uhlandstraße 60</td>\n",
       "      <td>[Übersicht, Klassen, Videos, Preise, Team]</td>\n",
       "      <td>Die Tanzschule Poledance Reutlingen befindet s...</td>\n",
       "      <td>info@poledance-reutlingen.de</td>\n",
       "      <td>https://www.poledance-reutlingen.de</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.eversports.de/s/tanzschule-poledan...</td>\n",
       "      <td>[Rückenfit, Poledance, Poledance, Crossbody (H...</td>\n",
       "      <td>1 Angebot für Neukund:innen</td>\n",
       "      <td>2024-02-02 22:36:45</td>\n",
       "      <td>2024-02-02 22:36:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PoleStudio_Name                                Adresse  \\\n",
       "0                 LOFT1 BASEL CITY    [Centralbahnplatz 10 ,  4051 Basel]   \n",
       "1  Tanzschule Poledance Reutlingen  [Uhlandstraße 60 ,  72793 Pfullingen]   \n",
       "\n",
       "     PLZ       Stadt                Straße  \\\n",
       "0   4051       Basel  Centralbahnplatz 10    \n",
       "1  72793  Pfullingen      Uhlandstraße 60    \n",
       "\n",
       "                                      Buttons  \\\n",
       "0  [Übersicht, Klassen, Videos, Preise, Team]   \n",
       "1  [Übersicht, Klassen, Videos, Preise, Team]   \n",
       "\n",
       "                            Pole Studio Beschreibung  \\\n",
       "0  Hell und freundlich und mit 13 Stangen ausgest...   \n",
       "1  Die Tanzschule Poledance Reutlingen befindet s...   \n",
       "\n",
       "                          E-Mail                                Homepage  \\\n",
       "0                  info@loft1.ch  https://www.loft1.ch/studio-basel-2-2/   \n",
       "1   info@poledance-reutlingen.de     https://www.poledance-reutlingen.de   \n",
       "\n",
       "  Telefon                                              URL_S  \\\n",
       "0    None       https://www.eversports.de/s/loft1-basel-city   \n",
       "1    None  https://www.eversports.de/s/tanzschule-poledan...   \n",
       "\n",
       "                                                 Art  \\\n",
       "0  [Fitness, Poledance, Poledance, Fitness, Fitne...   \n",
       "1  [Rückenfit, Poledance, Poledance, Crossbody (H...   \n",
       "\n",
       "                        Angebot         Created Date         Updated Date  \n",
       "0  2 Angebote für Neukund:innen  2024-02-02 22:36:35  2024-02-02 22:36:35  \n",
       "1   1 Angebot für Neukund:innen  2024-02-02 22:36:45  2024-02-02 22:36:45  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_pole_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_workshop_details"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
